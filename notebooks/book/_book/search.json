[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Reproducible Analyses in R",
    "section": "",
    "text": "1 Introduction\nI am a Genomics Data Scientist with the Computational Biology Core at the Center for Computation and Visualization. I started at Brown in early 2019, before that I got my PhD in Biological and Environmental Sciences at University of Rhode Island. The goal of this workshop is to introduce you to a few of my favorite packages and approaches that help me make my R analyses more reproducible. I also wanted to thank my colleague, George Dang. He put together all of the stuff about OOD and helped me clarify some things about how I use containers. Thanks George!\nIf you have questions about anything we talk about here, come to our office hours (https://events.brown.edu/ccv/). In addition to the general Oscar office hours, you are also welcome to come by the Computational Biology Core office hours. Even if you aren’t a biologist, we can probably help you with your R code."
  },
  {
    "objectID": "containers.html",
    "href": "containers.html",
    "title": "2  Containers",
    "section": "",
    "text": "3 Docker containers\nI think the two changes that have the biggest impact on the reproducibility of my analysis is integrating version control (Git and GitHub) and containerization into my workflow. Others at CCV have given a workshop about Git at the 2023 Research Computing Bootcamp (‘Version Control with Git’: https://docs.ccv.brown.edu/bootcamp-2023/schuedule/wednesday-5-may). I won’t get into version control (other than to say that you should absolutely be using it) but will talk a tiny bit about how I use containers.\nContainers are sometimes described as “A light-weight virtual machine”, but for me they are just a very nice way to bundle up all of the software and packages I used to perform some analysis. I mostly use Docker containers, but they require root/admin privileges. In cases where I can’t get those privileges (like on Oscar, the Brown HPC), I run my Docker images as Singularity containers. What am I even saying?\nA bit of an overview: You build a Docker image from a Dockerfile. You can push the Docker image to DockerHub (or GitHub container registry) and track changes to the Dockerfile using GitHub. When you spin up a running version of that image, this is a Docker container. Once your Docker image is on DockerHub, a collaborator can run that container as an image on their local machine and use all the same packages that you did. If you want to make changes to the software available in the container, you make changes to the Dockerfile, re-build the Docker image, and run the updated Docker container. If you want to spin up an instance of the container on Oscar or some other computer where you don’t have root privileges, you are in luck because you can pull and run the Docker image as a Singularity container. Fabulous.\n\n\n\n\n\nI am a genomics data scientist, so the ‘raw’ data I am usually working with are reads from a sequencer. If all my raw sequencing data is uploaded to SRA or GEO or some similar platform, all my notebooks and scripts are on GitHub, and all of my Docker images are on Dockerhub, anyone else who wants to reproduce my analysis has all the data, code, and the computing environment necessary to reproduce what I’ve done. This helps me sleep soundly at night.\n99% of the time, I am using a Dockerfile that is based off of the images provided by The Rocker Project (https://rocker-project.org/images/). These are Docker containers designed specifically to be used with R and they are wonderful. Here’s an example of what a dockerfile looks like:\n\n\n\n\n\nThe first line specifies that we want to use the Docker image from the rocker organization, and that we want rstudio tagged with R version 4.3.1. The next few lines are installing some system level libraries (you might not need to add any system level libraries depending on what you’re doing). The last line is installing a few R packages from CRAN."
  },
  {
    "objectID": "bookdown_quarto.html",
    "href": "bookdown_quarto.html",
    "title": "3  Bookdown and Quarto",
    "section": "",
    "text": "4 Bookdown and Quarto\nAnother way to make your analysis more reproducible is to couple the data analysis with the code used to make it. A single RMarkdown (https://rmarkdown.rstudio.com/) file can do this, but it gets cumbersome as your analysis involves more and more steps.\nYou can use Bookdown (https://bookdown.org/) or Quarto (https://quarto.org/) to organize your analysis into chapters spread out across several notebook files. Quarto is new and is particularly nice because it works with R, Python, Julia, and Observable. It also has lots of output format options (https://quarto.org/docs/output-formats/all-formats.html) and templates including templates that make it easier to submit papers to journals (https://quarto.org/docs/extensions/listing-journals.html).\nI did this workshop in Quarto. There’s a file in reproducibility_r/notebooks/book called _quarto.yml that spells out all of the options I used with Quarto. After opening the project, you should be able to render this notebook if you run quarto::quarto_render(here::here('notebooks/book'), quiet = TRUE), then open index.html in reproducibility_r/notebooks/book/_book."
  },
  {
    "objectID": "ood.html",
    "href": "ood.html",
    "title": "4  Open On Demand",
    "section": "",
    "text": "5 Launching RStudio on Singularity with OOD\nIf you want to try to use the container I used to make this workshop, you can do that using Open On Demand:\n\nGo to ood.ccv.brown.edu and log in with your credentials.\nOn the landing page select the RStudio on Singularity app.\n\n\n\n\n\n\n\nFill in the following fields and leave the other fields empty\n\nNumber of Hours: 48\nNum Cores: 4\nMemory: 16\nSingularity Container Path: /gpfs/data/shared/databases/workshops/reproducibility_r/reproducibility_r.sif\nPath for R Executable: ~/bin/R\n\n\nIt should look like the two images below.\n\n\n\n\n\n\n\n\n\n\nIf it seems like it is taking too long, you can change Number of Hours to 1 for the purposes of following along with this workshop.\n\nSelect Launch. The session will now be queued. You will be brought to your interactive sessions dashboard.\nWhen the session is ready a Connect to RStudio Server button will appear (see image below). Click this button to launch your instance."
  },
  {
    "objectID": "here.html",
    "href": "here.html",
    "title": "5  Dealing with file paths using here",
    "section": "",
    "text": "6 Here\nWhen looking at someone elses R code, you might see scripts or notebooks with lines with hard-coded paths, like this:\n\ndata &lt;- read.table('/Users/Joselynn/Desktop/raw_data.txt')\n\nOr maybe start like this:\n\nsetwd('/Users/Joselynn/Desktop')\n\nThese approaches aren’t wrong, they are a bit fragile and could break when your colleagues try to run your code on their computers. One way to avoid this is to use RStudio projects and the here package. RStudio projects are nice because they let you keep separate working environments for different projects and do lots of other very nice things for you (https://support.posit.co/hc/en-us/articles/200526207-Using-RStudio-Projects). You can make new RStudio projects through the RStudio app or with the usethis package (https://usethis.r-lib.org/reference/index.html). I’ve already set this repository up as an RStudio project. You can open the project by going up to File &gt; Open Project and opening the reproducibility_r.Rproj in the base of this repo. Now you can use here to refer to paths:\n\nhere::here()\n\n[1] \"/users/jwalla12/reproducibility_r\"\n\n\nAnd you can build up full paths like this:\n\nlist.files(here::here('notebooks/book/_book'))\n\ncharacter(0)\n\n\nYou can setwd to change the working directory and here::here should still work:\n\nsetwd('~')\ngetwd()\n\n[1] \"/users/jwalla12\"\n\nhere::here()\n\n[1] \"/users/jwalla12/reproducibility_r\""
  },
  {
    "objectID": "assertr.html",
    "href": "assertr.html",
    "title": "6  Data verification with assertr",
    "section": "",
    "text": "7 assertr\nAnother package that could help with making your data analysis more reproducible is assertr (https://cran.r-project.org/web/packages/assertr/assertr.pdf). It is basically a suite of functions to check that your data meets some of your assumptions before you proceed with your analysis.\n\nlibrary(magrittr)\nlibrary(assertr)\n\nLet’s work with the mtcars data. The mpg column is an example of data that shouldn’t have any negative values:\n\nhead(mtcars)\n\n                   mpg cyl disp  hp drat    wt  qsec vs am gear carb\nMazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\nValiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1\n\nmtcars %&gt;%\n  dplyr::group_by(cyl) %&gt;%\n  dplyr::summarise(avg.mpg=mean(mpg))\n\n# A tibble: 3 × 2\n    cyl avg.mpg\n  &lt;dbl&gt;   &lt;dbl&gt;\n1     4    26.7\n2     6    19.7\n3     8    15.1\n\n\nWhat if this wasn’t true? We can mess with the data a little to see what happens..\n\nmtcars$mpg[5] \n\n[1] 18.7\n\nmtcars$mpg[5] &lt;- mtcars$mpg[5] * -1\n\nThen we can use assertr::verify to add a step where we confirm that we don’t have any negative values first, and if we do assertr will stop the process.\n\nmtcars %&gt;%\n  assertr::verify(mpg &gt;= 0) %&gt;%\n  dplyr::group_by(cyl) %&gt;%\n  dplyr::summarise(avg.mpg=mean(mpg))"
  }
]