---
title: "pdf_parsing"
format: html
editor: visual
---

## PDF parsing

Many scientific articles and documents are in PDF format. This isn't the easiest format for reproducible analysis, but here are packages to parse text information from PDFs.

I've saved a PDF of US GDP per year (also from Gap Minder). Let's use `pdftools` to import it. We will use the `pdf_ocr_text` function, which uses Optical Character Recognition to read the PDF.

```{r}
gm_gdp_us <- pdf_ocr_text(here('data/raw/GM_gdp_US.pdf'))
head(gm_gdp_us[[1]])
```

This looks very messy -- we can see lots of new line characters (`\n`) spread throughout the string. We can use `str_split` from `stringr` to split up the characters by the `\n` character.

```{r}
gm_gdp_us_split <- str_split(string = gm_gdp_us, pattern = "\n")
```

We've got a nested list -- use `unlist` to flatten it.

```{r}
gm_gdp_us_split_unlist <- unlist(gm_gdp_us_split)
```

Use `read.table` to convert into a dataframe, setting `row.names = NULL` will number the rows (instead of trying to use the column `row.names` to name them).

```{r}
gm_gdp_us_imported <- read.table(text = gm_gdp_us_split_unlist, row.names = NULL)
head(gm_gdp_us_imported)
```
